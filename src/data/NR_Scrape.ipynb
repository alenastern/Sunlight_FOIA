{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "import bs4\n",
    "import csv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape data from Albuquerque Next Request portal which has different url/data format than others\n",
    "\n",
    "cities = ['Albuquerque']\n",
    "\n",
    "for city in cities:\n",
    "    fn = '{}.csv'.format(city)\n",
    "    with open(fn, 'w') as csvfile:\n",
    "        fieldnames = ['id', 'status', 'requester', 'request', 'departments', 'cost', 'PoC']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = fieldnames, delimiter = ',')\n",
    "\n",
    "        writer.writeheader()\n",
    "        \n",
    "        req = requests.get('https://nextrequest.cabq.gov/requests')\n",
    "\n",
    "        for i in range(2, 479):\n",
    "            html = req.text.encode('utf8')\n",
    "            soup = bs4.BeautifulSoup(html, \"html5lib\")\n",
    "            rl = soup.tbody.find_all('tr', class_ = \" demo-data-false\") \n",
    "            for prr in rl:\n",
    "                cl = list(prr.children)\n",
    "                writer.writerow({'id': cl[1].a.strong.contents[0],\n",
    "                                'status': cl[3]['class'][1],\n",
    "                                'requester': cl[5].get_text().lstrip().rstrip(),\n",
    "                                'request': cl[7].a.contents[0].lstrip().rstrip(),\n",
    "                                'departments': cl[9].get_text().lstrip().rstrip(),\n",
    "                                'cost': cl[11].get_text().lstrip().rstrip().strip('$'),\n",
    "                                'PoC': cl[13].get_text().lstrip().rstrip()})\n",
    "            url = 'https://nextrequest.cabq.gov/requests?requests_smart_listing[page]={}'.format(i)\n",
    "            req = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oaklandca\n",
      "https://oaklandca.nextrequest.com/requests\n",
      "27122\n",
      "1085\n",
      "providenceri\n",
      "https://providenceri.nextrequest.com/requests\n",
      "2192\n",
      "88\n",
      "sanfrancisco\n",
      "https://sanfrancisco.nextrequest.com/requests\n",
      "1525\n",
      "61\n",
      "vallejo\n",
      "https://vallejo.nextrequest.com/requests\n",
      "340\n",
      "14\n",
      "westsacramento\n",
      "https://westsacramento.nextrequest.com/requests\n",
      "886\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# Scrape data from Next Request portals from list of cities given below\n",
    "\n",
    "cities = ['bainbridgewa', 'cityoflascruces', 'mercerisland', 'miami', 'middleboroughma', \n",
    "          'nola', 'oaklandca', 'providenceri', 'sanfrancisco', 'vallejo', 'westsacramento' ]\n",
    "\n",
    "for city in cities:\n",
    "    print(city)\n",
    "    fn = '{}.csv'.format(city)\n",
    "    with open(fn, 'w') as csvfile:\n",
    "        fieldnames = ['id', 'status', 'requester', 'request', 'departments', 'PoC']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = fieldnames, delimiter = ',')\n",
    "\n",
    "        writer.writeheader()\n",
    "        url = 'https://{}.nextrequest.com/requests'.format(city)\n",
    "        print(url)\n",
    "        \n",
    "        req = requests.get(url)\n",
    "        html = req.text.encode('utf8')\n",
    "        soup = bs4.BeautifulSoup(html, \"html5lib\")\n",
    "        \n",
    "        num_rec = int(soup.find_all('h2')[1].span.get_text().lstrip().rstrip())\n",
    "        print(num_rec)\n",
    "        num_page = math.ceil(num_rec/25)\n",
    "        print(num_page)\n",
    "\n",
    "        for i in range(2, num_page + 2):\n",
    "            rl = soup.tbody.find_all('tr', class_ = \" demo-data-false\") \n",
    "            for prr in rl:\n",
    "                cl = list(prr.children)\n",
    "                writer.writerow({'id': cl[1].a.strong.contents[0],\n",
    "                                'status': cl[3]['class'][1],\n",
    "                                'requester': cl[5].get_text().lstrip().rstrip(),\n",
    "                                'request': cl[7].a.contents[0].lstrip().rstrip(),\n",
    "                                'departments': cl[9].get_text().lstrip().rstrip(),\n",
    "                                'PoC': cl[11].get_text().lstrip().rstrip()})\n",
    "            url_2 = url+'?requests_smart_listing[page]={}'.format(i)\n",
    "            req = requests.get(url_2)\n",
    "            html = req.text.encode('utf8')\n",
    "            soup = bs4.BeautifulSoup(html, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
